<!DOCTYPE html>
<html>
  <head>
    <title>Introduction</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Garamond);
      @import url(https://fonts.googleapis.com/css?family=Muli:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);
    </style>
    <link rel="stylesheet" href="../style.css">
  </head>
  <body>
    <textarea id="source">

class: center, middle

### W4995 Applied Machine Learning

# Introduction

01/23/19

Andreas C. Müller

(Adapted and modified for CC 6021236 @ PCC/Ciencias/UCV by 

Eugenio Scalise, July 2019)

???

Hey and welcome to my course on Applied Machine Learning. As you can see we
have a pretty full class so make sure you don’t hog too much space.  I’m
Andreas Mueller, I’m a reseach scientist at the DSI and I spend some of my time working
on scikit-learn development. Also, I'm going on a first name basis with
people in the course, so you can call me Andy. If you have any feedback about
the class, feel free to send me an email or drop by my office hours. Also feel
free to interrupt me with questions. I’m not sure if that’ll work with so big a
class but I’m giving it a go. The goal of this class is to provide you with
the hands-on knowledge you need to be successful in applying machine learning
in the real world. It complements the Machine Learning course, but doesn’t rely
on it.  For those of you who have taken a machine learning class, or who are
taking it now, some things might be a bit redundant, but I promise you there’ll
be a lot of new stuff in this course. Who’s taking machine learning this
semester, raise your hand? And who has taken it before? And who hasn’t?
I'm recording all of these lectures and they'll go up on youtube.

FIXME examples of supervised learning?
FIXME add Chris Bishop's book?
FIXME books clickable links 

---

class: spacious

# What is machine learning?

- Machine learning is about extracting knowledge from data.

- It is a research field at the intersection of statistics, artificial intelligence, and computer science and is also known as predictive analytics or statistical learning.

- The application of machine learning methods has in recent years become ubiquitous in everyday life.

???

Machine learning is about extracting knowledge from data. It is closely related
to statistics and optimization. What distinguishes machine learning is that it
is very focused on prediction.

We want to learn from a large dataset how to make decisions for future
observations. You could say that the input to a machine learning program is
the dataset, and the output is a program that can make decisions on future
observations.

Machine learning is really widely used now, and I want to give you some
examples that most of you probably already interacted with today.

---

.center[
![:scale 70%](images/fb1.png)
]

???

Here’s the Facebook news-feed. There’s so much machine learning here, it’s crazy.
Can you point out some of them?
So the most space is a sponsored item. Facebook used ML to know who to show
this too. It’s clearly targetted at developers. Facebook also used ML to know
how much to charge for showing it. Then there’s a post below by a friend.
Facebook ranked that top most interesting to me right now, again ML. Then on
the right, you can see birthdays. It shows only one name, though there’s two
birthdays. Again ML to decide how many and whom to show. Below, trending
topics, apps to connect and people I might now. All ML.

---

.center[
![:scale 70%](images/facebook_gael.png)
]

???

But wait, there’s more. Here’s me uploading a picture. It finds the faces
of many of the people here, even in odd poses. Not only my friend Gael here,
one of the creators of scikit-learn, but also Jared Lander there in the background.

I'm pretty sure they could automatically tag the people, and actually describe the photos,
but that seems to be disabled on my account. My account might still be European,
where they don't tag faces because of privacy concerns.

---

.center[
![:scale 70%](images/fb3.png)
]

???

And then after you post an album, facebook will select some most interesting
pictures for you, and give them different kinds of space, to create a mosaic.

But that’s just facebook. Let’s see what else I’ve got open.

---

.center[
![:scale 70%](images/amazon1.png)
]

???

And then as a last example, amazon. Because google would have been too easy.
Here I’m searching for machine learning. I get a ranked list, using machine
learning. I get sub-categories to search in, via machine learning. Each book
has some features, like top seller etc, added with machine learning.  And
there’s an ad at the top, selected via machine learning.

---

.center[
![:scale 70%](images/amazon2.png)
]

???

And if I click on a book, more machine learning.
There’s an ad below for textbooks, targetted to me. There’s paperback as the
default choice, again machine learning. There’s frequently bought together, and
maybe less obviously, there’s a default seller! The price that is shown on the
right that’s selected for “add to cart” is also selected from a whole pool of
possible amazon sellers via machine learning.

Ok, that’s enough websites I think. While I went through all this, you were
probably on your phone, looking at more output produced by machine learning. My
point is, it’s everywhere. And often non-obvious, as in the case of selecting
a seller here.

---

# Science!

.center[
![:scale 70%](images/exoplanet.png)
]

???

That was some of the flashy, every day live applications. Something that might
get you VC funding. There’s also a lot of machine learning applications in less
visible, but equally important - or more important - applications in science.
There is more and more personalized cancer treatment – via machine learning.
More medical diagnosis, and more drug discovery are using machine learning.
The higgs boson couldn’t have been found without machine learning, and the same
is true for many earth like planets in other solar systems.
Which is shown using an artists illustration here. In reality you would
have a single pixel, containing the sun and the planet. You can find exoplanets
by checking whether the star gets periodically slightly darker, in which case you found
a planet. Of course with machine learning!
Machine learning is an essential in many data driven sciences now!  So no matter
where you want to go with data, you need machine learning.  But what does that
mean?  Next, I want to give you a little taxonomy of machine learning methods.

---
class: center, middle

# Types of Machine Learning

???

There are three main branches of machine learning.
Who can name them?
---
class: spacious

# Types of Machine Learning
- Supervised
- Unsupervised
- Reinforcement

???

They called supervised learning, unsupervised learning and reinforcement learning.
What are they?
This course will heavily focus on supervised learning, but you should be aware
the other types and their characteristics. We will do some unsupervised learning,
but no reinforcement learning. Supervised learning is the most commonly used type in
industry and research right now, though reinforcement learning becomes
increasingly important.

---

class: center

# Supervised Learning

.larger[
$$ (x_i, y_i) \propto p(x, y) \text{ independent identically distributed}$$
$$ x_i \in \mathbb{R}^p$$
$$ y_i \in \mathbb{R}$$
$$f(x_i) \approx y_i$$
]

???

In supervised learning, the dataset we learn form is input-output pairs (x_i,
y_i), where x_i is some n_dimensional input, or feature vector, and y_i is the
desired output we want to learn.  Generally, we assume these samples are drawn
from some unknown joint distribution p(x, y). In statistics, x_i might be
called independent variables and y_i dependent variable.
What does iid mean?
We say they are drawn iid, which stands for independent identically
distributed. In other words, the x_i, y_i pairs are independent and all come
from the same distribution p. You can think of this as there being some
process that goes from x_i to y_i, but that we don’t know. We write this as a
probability distribution and not as a function since even if there is a real
process creating y from x, this process might not be deterministic.  The goal
is to learn a function f so that for new inputs x for which we don’t observe y,
f(x) is close to y.  This approach is very similar to function approximation.
The name supervised comes from the fact that during learning, a supervisor
gives you the correct answers y_i.

---

# Generalization
.padding-top[
.left-column[
Not only


also for new data:
]

.right-column[$f(x_i) \approx y_i$,


$f(x) \approx y$
]]
???
For both regression and classification, it’s important to keep in mind the
concept of generalization.
Let’s say we have a regression task. We have features, that is data vectors x_i
and targets y_i drawn from a joint distribution. We now want to learn a
function f, such that f(x) is approximately y, not on this training data, but
on new data drawn from this distribution. This is what’s called generalization,
and this is a core distinction to function approximation. In principle we don’t
care about how well we do on x_i, we only care how well we do on new samples
from the distribution. We’ll go into much more detail about generalization in
about a week, when we dive into supervised learning. 

---
class: spacious

# Examples of Supervised Learning

- spam detection
- medical diagnosis
- adp click prediction

???

Here are some examples of supervised learning.
Given an array of test results from a patient, does this patient have diabetes?
The x_i would be the different test results, and y_i would be diabetes or no
diabetes.  Given a piece of a satellite image, what is the terrain in this
image? Here x_i would be the pixels of the image, and y_i would be the terrain
types.

This is often used to automate manual labor. For example, you might annotate
part of a dataset manually, then learn a machine learning model from this
annotations, and use the model to annotate the rest of your data.

---

# Unsupervised Learning
$$ x_i \propto p(x) \text{ i.i.d.}$$
Learn about $p$.

???

In unsupervised machine learning, we are just given data points x_i, that are
assumed to be drawn from an unknown distribution. Usually we want to learn
something about these, such as whether they lie on a low-dimensional subspace,
or whether the data clusters in several groups, or find ways to represent the
distribution compactly.  The goal in unsupervised learning is often much less
clear than in supervised learning, and there is no-one providing a “correct”
answers and no supervisor.

Common examples of unsupervised learning is discovering topics in news articles
or on twitter, or grouping data into clusters for easier analysis.  Another one
is outlier detection, where you ask “does this data look normal” which is
important for fraud detection and security systems.

---

class: center, middle

# Reinforcement Learning

.left-column[
![:scale 100%](images/alpha_go.png)
]

.right-column[
![:scale 100%](images/nao.png)
]

???

The third kind, reinforcement learning, has been in the news quite a bit in the
last year. Has anyone heard of that? Alpha go beat the world champion in go.
Reinforcement learning is about an agent learning to interact with an
environment, with some ultimate goal. The environment could be a go board, and
the goal to win the game. For self-driving cars, the the environment could be
roads, sensed by cameras and laser sensors, and the goal would be to get you
somewhere quickly and safely. Or, the environment could be a social media
platform, and the goal could be to provide you such great content that you
never remove your eyes from your phone again!


---

# Classification and Regression

.left-column[
### Classification
- target y discrete

- Will you pass?
]

.right-column[
### Regression
- target y continuous
- How many points will you get in the exam?
]
???
So getting back to supervised learning, there are two basic kinds, called
classification and regression.
The difference is quite simple: if y is continuous, then it’s regression, and
if y is discrete, it’s classification.

While it's simple, let me give an example.
If I want to predict whether a one of you will pass the class, it’s a
classification problem. There are two possible answers, “yes” and “no”.  If I
want to predict how many points you get on an exam, it’s a regression
problem, there is a continuous, gradual output space.

There are generalizations of this where we try to predict more than one
variable, but we won’t go into that in this course. The main reason the distinction
between classification and regression is important is because the way we
measure how good a prediction is is very different for the two.
It's not always entirely clear whether it's best to formulate a problem as classification
or regression. If you think of predicting a 5-star rating, there's only 5 different possible
outcomes, so you might think it's classification. But there is also an obvious ordering
between the outcomes, which would make it a regression problem.
Both formulations could work, and there are approaches that combine the two for
this particular problem.

---

# Relationship to Statistics

.left-column[
Statistics
- model first
- inference emphasis
]
.right-column[
Machine learning
- data first
- prediction emphasis
]

???

Before I’ll go into some general principles, I want to position machine
learning in relation to statistics. I recently got chewed out by a colleague
for doing that. My goal here is not to say one is better than the other.
Actually, there’s really no clear boundary between statistics and machine learning, and
anyone that tells you otherwise is lying. Two of the books I recommended for the
course are actually statistics text books. But I can tell you how the tools
that I’m talking about in this course will differ from what you’d learn in a
typical stats course.

Statistics is usually about inference, often phrased in terms of hypothesis
testing. An example might be a yes-no-question, such as “are women less likely
to enroll in a Data Science Program”, and you have a sample population, for
example this classroom, and you can then try to make an inference about whether
this statement is true. Often this includes making assumptions on how your
sample relates to the general population, say this class vs all of DSI or
Columbia vs all of the US. You might also have a specific model of how the process
behind your question works.

On the other hand, machine learning is about prediction and generalization. We
want to learn from past data to predict outcomes on future, unseen data.

We usually want to make statements about individual data points, and we want to
build a model that will work on new data that fulfills our assumptions,
independent of the population we samples. Often we don’t have or need a model
of the process, but we rely on the assumption that our training data is
generated from the same process as any future data will be.

There are statisticians that do predictions and there are machine learning
scientists that do inference, but I find this distinction helpful.

Again I’m not saying one or the other is better, I’m just saying that you should
know what kind of problem you are trying to solve, and what the right tool for
the problem is. And then you can call it machine learning or statistics or
probabilistic inference or data science. The tools you learn in this
class will usually not help you to make yes/no inferences, and they
will only give you a limited insight into the data generating process.

---

# The Machine Learning Work-Flow

![:scale 100%](images/ml-workflow.png)

???

Here is one possible depiction of the overall machine learning workflow.
In this class, I attempt to cover as many aspects of this as possible,
only leaving out the data collection.
I stole this illustration from a book on recommendation engines, but I mostly
agree with it.
Everything starts with the data generating process, in this diagram it’s the
user. You ingest the data, and preprocess it. Some of the preprocessed that is
held out for model validation. The rest is used for actually building the
model. Then, there’s the model debugging loop. You get results and you want to
improve them. That’s what’s shown as the train-test-loop. I would argue
sometimes this loop goes further back, and maybe you discover an issue as early
as in the ingestion. In the end, you find a model that you like, and you deploy
it. However, that’s not the end of the story! If you’re working with a life
system, the deployed model is likely to change user behavior, which means your
input data changes, and your model might not be applicable any more! That
feedback loop is really tricky, and we won’t go into that in this course. It’s
good to keep in mind when you all create your first startup, though.


---
class: center, middle

# Python basics

???
So now I want to go over some Python basics. And don’t worries, we
won’t go over syntax or the standard library.

---
class: spacious

# Why Python?

- General purpose language
- Great libraries
- Easy to learn / use
- Contenders: R (Scala? Julia?)

???
First, a short defense on why I’m teaching this class in Python.
Python is a general purpose programming language, unlike matlab or R,
so you can do anything with it.
It is very powerful, mostly because there are so many libraries for
python that you can do basically anything with just a couple of lines.
Python is arguably easy to learn and easy to use, and it allows for a
lot of interactivity.
The only real contender in the data science space that I can think of
is R, which is also a good option, but well, I’m not an R guy. Much
of this course could be taught in R instead, though the software
development tooling is a bit worse (but other things are better).
You might have better chances with Python in industry jobs.
There’s also Scala, but I’d argue that’s way too complicated and
doesn’t have the right tools for the kind of data analysis and machine
learning we want to do in this course.

---
class: spacious

# The two language problem

Python is sloooow…


- Numpy: C
- Scipy: C, fortran
- Pandas: Cython, Python
- Scikit-learn: Cython, Python

- CPython: C

???
So there’s one thing that I really  don’t like about Python. Any
idea what that is?
Python is slooow. Like really slow.
So you know all these great libraries for Python for data science, like
numpy, scipy, pandas and scikit-learn. Do you know what language they
are written in?
Numpy is written in C,
Scipy is written in C and Fortran, pandas and scikit-learn are written
in Cython and Python. And Cpython, the interpreter we use, is written
in … C obivously
That creates a bit of a divide between the users, who write python,
and the developers, who write C and Cython. I have to admit, I don’t
write a lot of Cython myself, mostly Python… but that’s not great.
So you need to be aware that if you actually want to implement new
algorithms, and you can’t express them with pandas and numpy, you
might need to learn cython.
For this course, this won’t really be a problem, though. We’ll stay
firmly on the Python side.


---

# Python 2 vs Python 3

- “current” : (2.7), 3.6, 3.7

- Don't use Python 2

???
There’s another thing that you could call the two language problem,
it’s python 2 vs python 3.
The last version of python 2 is python 2.7, and really no-one should be
using anything earlier. The commonly used versions of python 3 are 3.6 and 3.7.
There is really no reason to use python 2 any more and scikit-learn already doesn't
support it in it's current development version, same for numpy and matplotlib. Unless you already
wrote lots of code earlier. If you’re at a company it might not be
easy to make the  transition, and that’s why python 2 is still around.

So the important part are the changes. Anyone know what changed?

---
class: spacious

# Python ...

Package management:

- don't use system python!

- use Virtual environments

- understand pip (and wheels)

- probably use Conda (and anaconda or conda-forge)

???
Package management is really important if you want to become a serious python user.
Unfortunately, it’s a bit tricky, partly due to the two language problem, which
means packages have dependencies that are not in python.
First of, you should be aware of the environment you are using. Usually
it’s a good idea to work with virtual environments, in which you can
control what software is installed in what version. If you’re on OS X
or linux, your system will com with some python, but you don’t really
want to mess with that. Create your own environments, and are aware of
which environment you are using at any moment.
The standard python way to install packages is pip, which is part of
the setuptools package. Pip allows you to install all python packages in the pipy
repository, which is basically all of them.

Until not so long ago, pip needed to compile all C code locally on your
machine, which was pretty slow and complicated. Now, there are binary distributions,
called wheels, which mean no compilation for most packages! If you’re compiling
something when you’re installing, you’re probably doing it wrong.
The issue with pip is that it only works for python packages, and some
of our packages rely on linear algebra packages like blas and lapack,
and you need to install them some other way.
A really easy work-around for that is using a different package manager,
called conda. It was created by a company called Anaconda (used to be continuum
IO) and they ship a bundle called anaconda, which installs basically all the
important packages. I recommend you use that for the course.
Conda can be used with different source repositories. By default, it uses
the anaconda one that is managed by the company. There’s also an open
repository that is managed by the community that’s called conda-forge.
In practice I use both conda and pip.
---
class: some-space

# Pip and conda and upgrades

- Pip upgrade works on dependencies (unless you do -no-dep)

- pip has no dependency resolution!

- conda has dependency resolution

- Use conda environments!

- upgrading a conda package with pip (or vice versa) will break stuff!

???
Oh and one word of warning: if you do pip upgrade somepackage, it will
also update all the dependencies. That is often not what you want, in
particular if you are using it in a conda environment or if you installed
a particular version of numpy or scipy that you don’t want upgraded.
An imporatant thing to keep in mind about pip is that it has no dependency
resolution, which means it will install the dependencies for any
package you install, but it won't care about all the packages you installed
before. So whenever you're using pip to install something, it could potentially
break an already installed package.
Conda on the other hand has a dependency resolution mechanism, which means
it'll ensure that all the packages that you installed are compatible with each other.
Sometimes there are conflicts between packages, though, which might prevent
you from installing certain combinations.
The solution here is to make liberal use of conda environments.
If you need to work on a specific project, you should have a conda environment
for that project ant it's requirements. Conda environments are really very useful
and easy to use.

Finally, don't try to upgrade a package with pip if it was installed
with pip or the other way around. So if you mix conda and pip, make sure
you check which one you used before upgrading. I recommend to use conda
whenever possible.

---
# Environments and Jupyter Kernels
.smaller[
- Environment != kernels
- Use nb_conda_kernels or add environment kernels manually:

.smallest[
```bash
source activate myenv
python -m ipykernel install --user --name myenv --display-name "Python (myenv)"
source activate other-env
python -m ipykernel install --user --name other-env --display-name "Python (other-env)"
```
]
- https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/
]
.left-column[
![:scale 100%](images/kernel_other_env.png)
]
.right-column[
![:scale 100%](images/kernel_other_env2.png)
]
???

If you're using conda environments, you will want to use them in your jupyter notebooks.
However, jupyter is not immediately aware of your environments. Jupyter runtime environments
are defined by kernels, which can be python environments, or different programming languages.
You need to make sure that jupyter is aware of your environments to use them as a kernel.
One way is to manually add them by using this command here which invokes `ipykernel install`.
That works with any kind of python environment.
For conda environments specifically, you can also install the `nb_conda_kernels` package,
which will automatically create kernels for all environments that contain the `ipykernel`
package. If you do either of them, you'll get a choice of which kernel you want to use for
a notebook. That's a great way to use different versions of python, like 2 and 3, or different
versions of scikit-learn or matplotlib or anything else.

There is a bit more tooling around python that I want to talk about next.

---
class: spacious

# Dynamically typed, interpreted

- Invalid syntax lying around

- Code is less self-documenting

???
One of the reasons Python is so easy to learn and use is because it’s
a dynamically typed languages.
So who of you have worked with statically typed languages like C, C++,
Java or Scala?
It’s often a bit cumbersome that you have to declare the type of
everything, but it provides some safety nets. For example you know that
if the code compiles, the syntax is correct everywhere. You don’t know
whether the code does what you want, but you know it’ll do something.
Mabye crash your machine, but whatever.
Also, arguably, dynamically typed code is less self-documenting. If I write a
function without documentation, it’s very hard for you to guess what I
expect the input types to be. There’s now type annotations for Python,
which is great, but they are not supported in Python2 and are not adopted
everywhere yet. So how can we get back our safety nets?

---
class: spacious

# Editors

- Flake8 / pyflake

- Scripted / weak typing: Have a syntax checker!

- write pep8 (according to the standard, not the tool)

- use autopep8 if you have code lying around

???
One of the simplest fixes is to have a syntax checker in your
editor. Whatever editor you’re using, make sure you have something like
flake8 or pyflake installed that will tell you if you have obvious errors.
These will also tell you if you have unused imports, undeclared variables
or unused variables. All that helps you to immediately fix problems,
and not wait until you run your program.
I also recommend having a style checker. Flake8 also enforces pep8,
which is the python style guide.
You should write pep8 compatible code. It will make it easier for others
to read your code, and once you’re used to it, it’ll make it easier
for you to read other’s code.
If you want to convert code to be pep8 compatible, check out the autopep8
package. The pep8 tool is very strict these days, and I don't heed
all the warnings. There is a configuration file you can use to silence
the more obnoxious ones. When I say you should write pep9, I mean
you should write according to the standard, not the tool.
The first guideline of pep8 is to use your own judgment and not
blindly follow the guide.

---
class: middle

# Questions ?

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script>
    // Config Remark
    remark.macros['scale'] = function (percentage) {
        var url = this;
        return '<img src="' + url + '" style="width: ' + percentage + '" />';
    };
    config_remark = {
        highlightStyle: 'github',
        highlightSpans: true,
        highlightLines: true,
        ratio: "16:9"
    };
      var slideshow = remark.create(config_remark);

    // Configure MathJax
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] /* removed 'code' entry*/
    }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
    </script>
  </body>
</html>
